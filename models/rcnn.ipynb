{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the GPU if one exists.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert human readable str label to int.\n",
    "label_dict = {\"abw\": 0, \"pbw\" : 1}\n",
    "# Convert label int to human readable str.\n",
    "reverse_label_dict = {0: \"abw\", 1: \"pbw\"}\n",
    "\n",
    "class WormDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms = None):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            root: str\n",
    "                Path to the data folder.\n",
    "            transforms: Compose or list\n",
    "                Torchvision image transformations.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.files = sorted(os.listdir(\"images\"))\n",
    "        for i in range(len(self.files)):\n",
    "            self.files[i] = self.files[i].split(\".\")[0]\n",
    "            self.label_dict = label_dict\n",
    "    def __getitem__(self, i):\n",
    "        # Load image from the hard disc.\n",
    "        img = PIL.Image.open(os.path.join(self.root, \"images/\" + self.files[i] + \".png\")).convert(\"RGB\")\n",
    "        # Load annotation file from the hard disc.\n",
    "        ann = pd.read_csv(os.path.join(self.root, \"annotations/\" + self.files[i] + \".txt\"))\n",
    "        # The target is given as a dict.\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor([[ann[\"x1\"], \n",
    "                                            ann[\"y1\"], \n",
    "                                            ann[\"x2\"], \n",
    "                                            ann[\"y2\"]]], \n",
    "                                   dtype = torch.float32)\n",
    "        target[\"labels\"]=torch.as_tensor([label_dict[ann[\"label\"]]],\n",
    "                         dtype = torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor(i)\n",
    "        # Apply any transforms to the data if required.\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54557d5da701f14d6acbec16753c0b2a30b0c175a2c97d182468fef3f37829cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
