{"cells":[{"cell_type":"markdown","metadata":{"id":"XRZz1N0i534y"},"source":["## Helpful Links for Detectron2\n","- Guide to custom data training - https://www.analyticsvidhya.com/blog/2021/08/your-guide-to-object-detection-with-detectron2-in-pytorch/  \n","- Detectron2 configuration documentation - https://detectron2.readthedocs.io/en/latest/modules/config.html \n","- Github link https://github.com/facebookresearch/detectron2 \n","- Another custom data training guide - https://towardsdatascience.com/train-maskrcnn-on-custom-dataset-with-detectron2-in-4-steps-5887a6aa135d\n","\n","\n","### Possible help for errors\n","- https://stackoverflow.com/questions/69002169/json-annotations-error-string-indices-must-be-integers\n","- https://stackoverflow.com/questions/63012735/typeerror-string-indices-must-be-integers-while-trying-to-train-mask-rcnn-imple\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1598,"status":"ok","timestamp":1669045120483,"user":{"displayName":"Matthew Harding","userId":"01600842745932011593"},"user_tz":300},"id":"wbi_s6IJpQ7D","outputId":"c1b51ef1-d2ce-4a53-cc9f-ca98c655e4d1"},"outputs":[],"source":["import json\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","\n","\n","def load_data(t=\"train\"):\n","    if t == \"train\":\n","        with open(\"../data/detectron2/training/training.json\", 'r') as file:\n","            train = json.load(file)\n","        return train\n","    elif t == \"val\":\n","      with open(\"../data/detectron2/validation/validation.json\", 'r') as file:\n","          val = json.load(file)\n","    return val"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669045120483,"user":{"displayName":"Matthew Harding","userId":"01600842745932011593"},"user_tz":300},"id":"HHYWBZZuxfYW"},"outputs":[],"source":["from detectron2.config import get_cfg\n","from detectron2 import model_zoo\n","import os\n","\n","\n","def custom_config(num_classes):\n","    cfg = get_cfg()\n","\n","    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","\n","    cfg.MODEL.MASK_ON = True\n","\n","    cfg.DATASETS.TRAIN = (\"train\",)\n","    cfg.DATASETS.TEST = (\"val\",)\n","\n","    cfg.DATALOADER.NUM_WORKERS = 2\n","    cfg.SOLVER.IMS_PER_BATCH = 1\n","    cfg.SOLVER.BASE_LR = 0.001\n","    cfg.SOLVER.MAX_ITER = 5000\n","\n","    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32   # faster, enough for this dataset (default: 512)\n","    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n","\n","    cfg.MODEL.DEVICE='cpu'\n","    \n","    cfg.OUTPUT_DIR = \"mask_worms\"\n","\n","    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","    \n","    return cfg"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["for d in [\"train\", \"val\"]:\n","    DatasetCatalog.register(d, lambda d=d: load_data(d))\n","    MetadataCatalog.get(d).set(thing_classes=[\"abw\", \"pbw\"])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32m[11/22 16:40:16 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[11/22 16:40:16 d2.data.build]: \u001b[0mRemoved 4374 images with no usable annotations. 4389 images left.\n","\u001b[32m[11/22 16:40:16 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|\n","|    abw     | 183          |    pbw     | 116144       |\n","|            |              |            |              |\n","|   total    | 116327       |            |              |\u001b[0m\n","\u001b[32m[11/22 16:40:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[11/22 16:40:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[11/22 16:40:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n","\u001b[32m[11/22 16:40:16 d2.data.common]: \u001b[0mSerializing 4389 elements to byte tensors and concatenating them all ...\n","\u001b[32m[11/22 16:40:16 d2.data.common]: \u001b[0mSerialized dataset takes 18.23 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/22 16:40:16 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"]},{"name":"stderr","output_type":"stream","text":["Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32m[11/22 16:40:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/Caskroom/miniforge/base/envs/detectron2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646603923/work/aten/src/ATen/native/TensorShape.cpp:3191.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32m[11/22 16:40:48 d2.utils.events]: \u001b[0m eta: 1:58:09  iter: 19  total_loss: 2.717  loss_cls: 1.004  loss_box_reg: 0.7893  loss_mask: 0.6932  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.03198  time: 1.4876  data_time: 0.0942  lr: 1.9981e-05  \n","\u001b[32m[11/22 16:41:20 d2.utils.events]: \u001b[0m eta: 2:08:09  iter: 39  total_loss: 2.441  loss_cls: 0.7954  loss_box_reg: 0.85  loss_mask: 0.6641  loss_rpn_cls: 0.0456  loss_rpn_loc: 0.03639  time: 1.5574  data_time: 0.0007  lr: 3.9961e-05  \n","\u001b[32m[11/22 16:41:52 d2.utils.events]: \u001b[0m eta: 2:08:51  iter: 59  total_loss: 2.245  loss_cls: 0.6259  loss_box_reg: 0.8866  loss_mask: 0.6231  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.02335  time: 1.5660  data_time: 0.0006  lr: 5.9941e-05  \n","\u001b[32m[11/22 16:42:26 d2.utils.events]: \u001b[0m eta: 2:10:25  iter: 79  total_loss: 2.085  loss_cls: 0.5141  loss_box_reg: 0.8405  loss_mask: 0.5803  loss_rpn_cls: 0.03938  loss_rpn_loc: 0.03102  time: 1.5944  data_time: 0.0007  lr: 7.9921e-05  \n","\u001b[32m[11/22 16:42:57 d2.utils.events]: \u001b[0m eta: 2:09:12  iter: 99  total_loss: 1.928  loss_cls: 0.4576  loss_box_reg: 0.8407  loss_mask: 0.5098  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.1023  time: 1.5926  data_time: 0.0006  lr: 9.9901e-05  \n","\u001b[32m[11/22 16:43:31 d2.utils.events]: \u001b[0m eta: 2:11:24  iter: 119  total_loss: 1.771  loss_cls: 0.3735  loss_box_reg: 0.8288  loss_mask: 0.4592  loss_rpn_cls: 0.03778  loss_rpn_loc: 0.02802  time: 1.6051  data_time: 0.0006  lr: 0.00011988  \n","\u001b[32m[11/22 16:44:04 d2.utils.events]: \u001b[0m eta: 2:11:27  iter: 139  total_loss: 1.657  loss_cls: 0.3463  loss_box_reg: 0.7576  loss_mask: 0.4017  loss_rpn_cls: 0.0526  loss_rpn_loc: 0.04245  time: 1.6170  data_time: 0.0006  lr: 0.00013986  \n","\u001b[32m[11/22 16:44:37 d2.utils.events]: \u001b[0m eta: 2:11:43  iter: 159  total_loss: 1.794  loss_cls: 0.3693  loss_box_reg: 0.8022  loss_mask: 0.4026  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.0757  time: 1.6208  data_time: 0.0006  lr: 0.00015984  \n","\u001b[32m[11/22 16:45:10 d2.utils.events]: \u001b[0m eta: 2:11:32  iter: 179  total_loss: 1.474  loss_cls: 0.2743  loss_box_reg: 0.6988  loss_mask: 0.3626  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.0459  time: 1.6233  data_time: 0.0008  lr: 0.00017982  \n","\u001b[32m[11/22 16:45:42 d2.utils.events]: \u001b[0m eta: 2:09:50  iter: 199  total_loss: 1.666  loss_cls: 0.3839  loss_box_reg: 0.6839  loss_mask: 0.388  loss_rpn_cls: 0.02645  loss_rpn_loc: 0.115  time: 1.6205  data_time: 0.0006  lr: 0.0001998  \n","\u001b[32m[11/22 16:46:14 d2.utils.events]: \u001b[0m eta: 2:08:50  iter: 219  total_loss: 1.439  loss_cls: 0.2995  loss_box_reg: 0.6359  loss_mask: 0.357  loss_rpn_cls: 0.03256  loss_rpn_loc: 0.06069  time: 1.6175  data_time: 0.0006  lr: 0.00021978  \n","\u001b[32m[11/22 16:46:47 d2.utils.events]: \u001b[0m eta: 2:07:13  iter: 239  total_loss: 1.283  loss_cls: 0.2799  loss_box_reg: 0.6013  loss_mask: 0.3513  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.0352  time: 1.6194  data_time: 0.0007  lr: 0.00023976  \n","\u001b[32m[11/22 16:47:19 d2.utils.events]: \u001b[0m eta: 2:07:19  iter: 259  total_loss: 1.36  loss_cls: 0.2888  loss_box_reg: 0.6217  loss_mask: 0.3382  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.05509  time: 1.6197  data_time: 0.0006  lr: 0.00025974  \n","\u001b[32m[11/22 16:47:50 d2.utils.events]: \u001b[0m eta: 2:06:10  iter: 279  total_loss: 1.277  loss_cls: 0.2809  loss_box_reg: 0.5944  loss_mask: 0.3322  loss_rpn_cls: 0.02631  loss_rpn_loc: 0.0477  time: 1.6129  data_time: 0.0007  lr: 0.00027972  \n","\u001b[32m[11/22 16:48:25 d2.utils.events]: \u001b[0m eta: 2:07:07  iter: 299  total_loss: 1.494  loss_cls: 0.3247  loss_box_reg: 0.6794  loss_mask: 0.3788  loss_rpn_cls: 0.03345  loss_rpn_loc: 0.0701  time: 1.6230  data_time: 0.0006  lr: 0.0002997  \n","\u001b[32m[11/22 16:48:58 d2.utils.events]: \u001b[0m eta: 2:07:24  iter: 319  total_loss: 1.223  loss_cls: 0.2558  loss_box_reg: 0.5415  loss_mask: 0.3411  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.05301  time: 1.6250  data_time: 0.0008  lr: 0.00031968  \n","\u001b[32m[11/22 16:49:32 d2.utils.events]: \u001b[0m eta: 2:07:22  iter: 339  total_loss: 1.426  loss_cls: 0.2719  loss_box_reg: 0.634  loss_mask: 0.3039  loss_rpn_cls: 0.01551  loss_rpn_loc: 0.02462  time: 1.6302  data_time: 0.0006  lr: 0.00033966  \n","\u001b[32m[11/22 16:50:07 d2.utils.events]: \u001b[0m eta: 2:06:54  iter: 359  total_loss: 1.459  loss_cls: 0.3348  loss_box_reg: 0.6508  loss_mask: 0.3281  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.05819  time: 1.6365  data_time: 0.0006  lr: 0.00035964  \n","\u001b[32m[11/22 16:50:40 d2.utils.events]: \u001b[0m eta: 2:06:40  iter: 379  total_loss: 1.609  loss_cls: 0.394  loss_box_reg: 0.6177  loss_mask: 0.2999  loss_rpn_cls: 0.03959  loss_rpn_loc: 0.1487  time: 1.6367  data_time: 0.0007  lr: 0.00037962  \n","\u001b[32m[11/22 16:51:14 d2.utils.events]: \u001b[0m eta: 2:06:22  iter: 399  total_loss: 1.342  loss_cls: 0.3291  loss_box_reg: 0.565  loss_mask: 0.2902  loss_rpn_cls: 0.03355  loss_rpn_loc: 0.04478  time: 1.6391  data_time: 0.0010  lr: 0.0003996  \n","\u001b[32m[11/22 16:51:48 d2.utils.events]: \u001b[0m eta: 2:05:56  iter: 419  total_loss: 1.483  loss_cls: 0.341  loss_box_reg: 0.5951  loss_mask: 0.2942  loss_rpn_cls: 0.0385  loss_rpn_loc: 0.09372  time: 1.6429  data_time: 0.0006  lr: 0.00041958  \n","\u001b[32m[11/22 16:52:20 d2.utils.events]: \u001b[0m eta: 2:04:42  iter: 439  total_loss: 1.208  loss_cls: 0.3279  loss_box_reg: 0.5407  loss_mask: 0.3172  loss_rpn_cls: 0.03183  loss_rpn_loc: 0.07466  time: 1.6409  data_time: 0.0006  lr: 0.00043956  \n","\u001b[32m[11/22 16:52:54 d2.utils.events]: \u001b[0m eta: 2:04:28  iter: 459  total_loss: 1.37  loss_cls: 0.3224  loss_box_reg: 0.5745  loss_mask: 0.287  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.05875  time: 1.6422  data_time: 0.0010  lr: 0.00045954  \n","\u001b[32m[11/22 16:53:26 d2.utils.events]: \u001b[0m eta: 2:03:42  iter: 479  total_loss: 1.348  loss_cls: 0.3757  loss_box_reg: 0.5836  loss_mask: 0.2665  loss_rpn_cls: 0.02413  loss_rpn_loc: 0.08899  time: 1.6420  data_time: 0.0006  lr: 0.00047952  \n","\u001b[32m[11/22 16:53:59 d2.utils.events]: \u001b[0m eta: 2:03:10  iter: 499  total_loss: 1.234  loss_cls: 0.2694  loss_box_reg: 0.5148  loss_mask: 0.3092  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.05628  time: 1.6422  data_time: 0.0006  lr: 0.0004995  \n","\u001b[32m[11/22 16:54:31 d2.utils.events]: \u001b[0m eta: 2:02:33  iter: 519  total_loss: 1.464  loss_cls: 0.2232  loss_box_reg: 0.5773  loss_mask: 0.286  loss_rpn_cls: 0.02819  loss_rpn_loc: 0.02519  time: 1.6395  data_time: 0.0006  lr: 0.00051948  \n","\u001b[32m[11/22 16:55:02 d2.utils.events]: \u001b[0m eta: 2:01:55  iter: 539  total_loss: 1.235  loss_cls: 0.2314  loss_box_reg: 0.5404  loss_mask: 0.338  loss_rpn_cls: 0.008437  loss_rpn_loc: 0.02803  time: 1.6359  data_time: 0.0006  lr: 0.00053946  \n","\u001b[32m[11/22 16:55:35 d2.utils.events]: \u001b[0m eta: 2:01:31  iter: 559  total_loss: 1.421  loss_cls: 0.3302  loss_box_reg: 0.5947  loss_mask: 0.2989  loss_rpn_cls: 0.04351  loss_rpn_loc: 0.06301  time: 1.6370  data_time: 0.0006  lr: 0.00055944  \n","\u001b[32m[11/22 16:56:02 d2.utils.events]: \u001b[0m eta: 2:00:27  iter: 579  total_loss: 1.229  loss_cls: 0.2832  loss_box_reg: 0.5111  loss_mask: 0.2958  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.07567  time: 1.6266  data_time: 0.0006  lr: 0.00057942  \n","\u001b[32m[11/22 16:56:32 d2.utils.events]: \u001b[0m eta: 1:59:15  iter: 599  total_loss: 1.338  loss_cls: 0.3089  loss_box_reg: 0.5546  loss_mask: 0.2861  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.07611  time: 1.6225  data_time: 0.0006  lr: 0.0005994  \n","\u001b[32m[11/22 16:57:01 d2.utils.events]: \u001b[0m eta: 1:58:15  iter: 619  total_loss: 1.198  loss_cls: 0.2774  loss_box_reg: 0.579  loss_mask: 0.2679  loss_rpn_cls: 0.03986  loss_rpn_loc: 0.03039  time: 1.6170  data_time: 0.0006  lr: 0.00061938  \n","\u001b[32m[11/22 16:57:31 d2.utils.events]: \u001b[0m eta: 1:57:19  iter: 639  total_loss: 1.343  loss_cls: 0.2973  loss_box_reg: 0.6299  loss_mask: 0.3175  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.03127  time: 1.6139  data_time: 0.0006  lr: 0.00063936  \n","\u001b[32m[11/22 16:58:04 d2.utils.events]: \u001b[0m eta: 1:56:56  iter: 659  total_loss: 1.1  loss_cls: 0.2093  loss_box_reg: 0.5352  loss_mask: 0.24  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.03523  time: 1.6143  data_time: 0.0010  lr: 0.00065934  \n","\u001b[32m[11/22 16:58:35 d2.utils.events]: \u001b[0m eta: 1:56:10  iter: 679  total_loss: 1.514  loss_cls: 0.3101  loss_box_reg: 0.5218  loss_mask: 0.3395  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.07375  time: 1.6127  data_time: 0.0006  lr: 0.00067932  \n","\u001b[32m[11/22 16:59:05 d2.utils.events]: \u001b[0m eta: 1:55:20  iter: 699  total_loss: 1.128  loss_cls: 0.2153  loss_box_reg: 0.5831  loss_mask: 0.2532  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.03742  time: 1.6094  data_time: 0.0006  lr: 0.0006993  \n","\u001b[32m[11/22 16:59:35 d2.utils.events]: \u001b[0m eta: 1:54:09  iter: 719  total_loss: 1.345  loss_cls: 0.3116  loss_box_reg: 0.59  loss_mask: 0.2972  loss_rpn_cls: 0.02221  loss_rpn_loc: 0.03603  time: 1.6063  data_time: 0.0006  lr: 0.00071928  \n","\u001b[32m[11/22 17:00:06 d2.utils.events]: \u001b[0m eta: 1:53:22  iter: 739  total_loss: 1.214  loss_cls: 0.2624  loss_box_reg: 0.558  loss_mask: 0.2783  loss_rpn_cls: 0.03156  loss_rpn_loc: 0.03183  time: 1.6044  data_time: 0.0006  lr: 0.00073926  \n","\u001b[32m[11/22 17:00:37 d2.utils.events]: \u001b[0m eta: 1:52:47  iter: 759  total_loss: 1.212  loss_cls: 0.2815  loss_box_reg: 0.5607  loss_mask: 0.2667  loss_rpn_cls: 0.03141  loss_rpn_loc: 0.1097  time: 1.6036  data_time: 0.0006  lr: 0.00075924  \n"]}],"source":["from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.engine import DefaultTrainer\n","    \n","metadata = MetadataCatalog.get(\"train\")\n","\n","cfg = custom_config(2)\n","\n","\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from detectron2.engine import DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer, ColorMode\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","\n","\n","def visualization(metadata, cfg, test_set):\n","    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8\n","    predictor = DefaultPredictor(cfg)\n","    for d in test_set:\n","        im = cv2.imread(d[\"file_name\"])\n","        outputs = predictor(\n","            im)\n","        v = Visualizer(im[:, :, ::-1],\n","                       metadata=metadata,\n","                       scale=0.5,\n","                       instance_mode=ColorMode.IMAGE_BW\n","                       )\n","        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","        img = cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_RGBA2RGB)\n","        plt.imsave(os.path.join(os.path.join(cfg.OUTPUT_DIR, 'visualization'), str(d[\"image_id\"]) + '.png'), img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPxT5LBLVwGbKroswAGs2KL","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.15 ('detectron2')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"ed31e99e43def4124269cc29c7928ad2fdd36e5879fefe5ca3b677b25c52a633"}}},"nbformat":4,"nbformat_minor":0}
